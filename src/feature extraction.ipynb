{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm\n",
    "import math\n",
    "from nltk import ngrams\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, model_selection, svm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_model():\n",
    "    '''\n",
    "    - Make a list(list()) that will store the count of n-grams occuring in each\n",
    "      comment. This list() will later be used to compute the tf-idf feature matrix.\n",
    "    - Also, we will make a n_grams dict() that will contain all the char n_grams \n",
    "      appearing in all the comments.\n",
    "    '''\n",
    "\n",
    "    global n_grams_list, n_grams\n",
    "    n_grams_list = list()\n",
    "    n_grams = dict()\n",
    "\n",
    "    # Read the comments.txt file and find the n_grams in each comment.\n",
    "    comments = open(\"../train/comments.txt\", \"r\").readlines()\n",
    "\n",
    "    for comment in comments:\n",
    "        char_n_grams = list(ngrams(comment[:-1], 3))\n",
    "        char_n_grams = [\"_\".join(n_gram) for n_gram in char_n_grams]\n",
    "        n_grams_list.append(char_n_grams)\n",
    "\n",
    "        char_n_grams = set(char_n_grams)\n",
    "        for n_gram in char_n_grams:\n",
    "            if n_gram in n_grams.keys():\n",
    "                n_grams[n_gram] += 1\n",
    "            else:\n",
    "                n_grams[n_gram] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features():\n",
    "    '''\n",
    "    - Character n-grams(trigrams) are used for feature extraction.\n",
    "    - Build a vector of feature vectors for each of the tweets. \n",
    "    - The feature vector for each tweet will be of length (no. of trigrams) \n",
    "      with each feature being 0 or 1 marking the presence/absence of the \n",
    "      trigram in that particular tweet.\n",
    "    - So the features matrix will be of dim [(no. of comments) x (no. of trigrams)]\n",
    "    '''\n",
    "\n",
    "    global f_matrix\n",
    "    f_matrix = list()\n",
    "    D = len(n_grams_list)\n",
    "    \n",
    "    for comment_n_grams in tqdm(n_grams_list):\n",
    "        f_vector = list()\n",
    "        for n_gram in n_grams.keys():\n",
    "            # calculate tf-idf of the n_gram and append the tf-idf to the f_vector\n",
    "            # tf = [ N(occurences of n_gram in comment) / N(occurences of all the n_grams in the comment) ]\n",
    "            # idf = log { (total no. of comments) / (no. of comments the n_gram has appeared in) }\n",
    "            tf = (0.1 * comment_n_grams.count(n_gram)) / len(comment_n_grams)\n",
    "            idf = math.log(D) / n_grams[n_gram]\n",
    "            w = tf * idf\n",
    "            f_vector.append(w)\n",
    "\n",
    "        f_matrix.append(f_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_f_matrix():\n",
    "    f_matrix_writer = open(\"../train/feature_matrix.txt\", \"a\")\n",
    "    for f_vector in f_matrix:\n",
    "        f_vector = [str(f) for f in f_vector]\n",
    "        f_str = \",\".join(f_vector)\n",
    "        f_matrix_writer.write(str(f_str) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "language_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12308/12308 [05:42<00:00, 25.90it/s]\n"
     ]
    }
   ],
   "source": [
    "extract_features()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_f_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
